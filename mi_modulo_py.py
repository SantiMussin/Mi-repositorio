# -*- coding: utf-8 -*-
"""mi modulo.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WnOlVVQCx9LkC03Ssr6SITaChblnLWkw
"""

from scipy.stats import expon
from scipy.stats import t
from scipy.stats import chi2
from numpy.random import randint
import matplotlib.pyplot as plt
import numpy as np
import statsmodels as sm
from scipy.stats import norm

class ResumenNumerico:
  def __init__(self,datos):
    self.datos=datos

  def calculo_de_media(self):
    media=np.mean(self.datos)
    return media

  def calculo_de_mediana(self):
    mediana=np.median(self.datos)
    return mediana

  def calculo_de_desvio_estandar(self):
    desvio=np.std(self.datos)
    return desvio

  def calculo_de_cuartiles(self):
    q1=np.percentile(self.datos,25)
    q2=np.percentile(self.datos,50)
    q3=np.percentile(self.datos,75)
    return [q1, q2, q3]

  def resumen_numerico(self):
    res_num = {
    'Media': self.calculo_de_media(self.datos),
    'Mediana': self.calculo_de_mediana(self.datos),
    'Desvio': self.calculo_de_desvio_estandar(self.datos),
    'Cuartiles': self.calculo_de_cuartiles(self.datos),
    'Mínimo': min(self.datos),
    'Máximo': max(self.datos)
    }
    return res_num


class ResumenGrafico:
  def __init__(self,datos):
    self.datos = np.array(datos)

  def miqqplot(self):
    data_ord = np.sort(self.datos)
    desvio = np.std(data_ord)
    media = np.mean(data_ord)
    x_ord_s = data_ord-media/desvio
    cuantiles_teoricos = []
    for i in range(1,len(self.datos)+1):
      cuantiles_teoricos.append(norm.ppf(i/(len(self.datos+1))))

    plt.scatter(cuantiles_teoricos, x_ord_s, color='blue', marker='o')
    plt.xlabel('Cuantiles teóricos')
    plt.ylabel('Cuantiles muestrales')
    plt.plot(cuantiles_teoricos,cuantiles_teoricos , linestyle='-', color='red')
    plt.show()

    return cuantiles_teoricos

  def evaluacion_histograma(self, h, X):
    maximo = np.max(X)
    minimo = np.min(X)
    vectores = np.arange(minimo,maximo+3*h,h)
    datos_en_rango = []

    for i in range(len(vectores)-1):
      cantidad_datos = 0
      for x in self.datos:
        if x>vectores[i] and x<=vectores[i+1]:
          cantidad_datos = cantidad_datos+1
      datos_en_rango = datos_en_rango+[cantidad_datos]

    datos_en_rango = np.array(datos_en_rango)
    densidad_en_rango = ((datos_en_rango)/len(self.datos))/h

    evaluacion = []

    for i in range(len(vectores)-1):
      for j in X:
        if j>vectores[i] and j<=vectores[i+1]:
         evaluacion=evaluacion+[densidad_en_rango[i]]

    if minimo<=vectores[0]:
      evaluacion.append(densidad_en_rango[0])

    return evaluacion

  def kernel_gaussiano(self,u):
    valor_kernel_gaussiano = 1/(np.sqrt(2*np.pi)) * (np.e **(-0.5 * (u**2)))
    return valor_kernel_gaussiano

  def mi_densidad(self,values,h,kernel):
    density = []
    if kernel == "uniforme":
      for x in values:
        cant_adentro = 0
        for Xi in self.datos:
          if -1/2 < (Xi - x)/h <= 1/2:
            cant_adentro += 1
        density.append(cant_adentro/(len(self.datos)*h))

    if kernel == "gaussiano":
      for x in values:
        cant_adentro = 0
        for Xi in self.datos:
          u = (Xi - x) / h
          gauss = self.kernel_gaussiano(u)
          cant_adentro += gauss
        density.append(cant_adentro/(len(self.datos)*h))
    return density

class GeneradoraDeDatos:
  def __init__(self,ndatos):
    self.n=ndatos

  def generar_datos_dist_norm(self,media,varianza):
    datos_normal=np.random.normal(media,varianza,self.n)
    return datos_normal

  def generar_datos_exponenciales(self,n):
    datos_exponenciales=expon.rvs(0,1,size=n)
    return datos_exponenciales

  def generar_datos_BS(self):
    u = np.random.uniform(size=(self.n,))
    y = u.copy()
    ind = np.where(u > 0.5)[0]
    y[ind] = np.random.normal(0, 1, size=len(ind))
    for j in range(5):
        ind = np.where((u > j * 0.1) & (u <= (j+1) * 0.1))[0]
        y[ind] = np.random.normal(j/2 - 1, 1/10, size=len(ind))
    return y

  def generar_datos_Tstudent(self,n,grados_libertad):
    datos=t.rvs(df=grados_libertad, size=n)
    return datos

  def generar_datos_uniforme(self,n):
    datos_uniforme=np.random.uniform(0,1,n)
    return datos_uniforme

  def teorica_normal(self,grilla,media,varianza):
    densidad_teorica=norm.pdf(grilla,media,varianza)
    return densidad_teorica

  def teorica_BS(self,datos):
    sum=0
    for x in range(5):
      a=norm.pdf(datos,(x/2)-1,1/10)
      sum+=a

    densidad=0.5*norm.pdf(datos,0,1)+sum*0.1
    return densidad

  def teorica_exponencial(self,grilla):
    teorica=np.exp(grilla)
    return teorica

class Regresion:
  def __init__(self,x,y):
    self.x=x
    self.y=y

  def predecir(self,x_new):
    X_new = sm.add_constant(np.array([[1, x_new]]))
    prediccion = self.modelo.get_prediction(X_new)
    return prediccion

class RegresionLineal(Regresion):

  def ajustar_modelo(self):
    X = sm.add_constant(self.x)
    modelo = sm.OLS(self.y, X)
    self.modelo_ajustado = modelo.fit()
    return self.modelo_ajustado

  def supuestos_y_recta(self):
    parametros = self.modelo_ajustado.params
    for x in parametros[1:]:
      y_estimada = parametros[0] + x*self.X

      plt.figure(1)
      plt.scatter(self.x, self.y, marker="o", facecolors="none", edgecolors="blue")
      plt.xlabel("Años de Experiencia")
      plt.ylabel("Salario");
      plt.plot(self.x,y_estimada)

    plt.figure(2)
    residuos=self.modelo.resid()
    plt.scatter(residuos,y_estimada)
    plt.xlabel("Y-estimada")
    plt.ylabel("Residuos")

    plt.figure(3)
    inicio_ResumenGrafico=ResumenGrafico(residuos)
    qqplot = inicio_ResumenGrafico.miqqplot()

    plt.show

    def t_obs(self,alfa,h1):

      SE_est = self.modelo.bse
      coef_x = self.modelo.params[1]
      t_obs=(coef_x-h1)/SE_est[1]
      n = len(self.x)
      df = n-2
      t_critico = t.ppf(1-(alfa/2),df)
      p_valor = 2*(1-(t.cdf(abs(t_obs),df)))
      return print('t observado:',t_obs,'La región de rechazo es: $$R=(-∞,',-1*t_critico,') ∪ (',t_critico,',∞),$$) P-valor:',p_valor)


class RegresionLogistica(Regresion):

  def ajustar_modelo(self):
    X = sm.add_constant(self.x)
    modelo = sm.Logit(self.y, X)
    resultado = modelo.fit()


class Dados:
  def __init__(self,tita,alfa,muestra):
    self.tita=tita
    self.alfa=alfa
    self.muestra=np.array(muestra)

  def boostrap(self,n):
    N=len(self.muestra)
    indices=[]
    for x in range(n):
      ind=randint(0,N)
      indices=indices+[ind]
    return self.muestra[indices]

  def intervalo_boostrap(self,N,n):
    titas_boot=[]
    z_critico=norm.ppf(q=1-self.alfa/2)

    for x in range(0,N):
      muestra=self.boostrap(n)
      tita_boot=(sum(muestra%2==0))/len(muestra)
      titas_boot.append(tita_boot)

    desvio_titas=np.std(titas_boot)
    intervalo=[self.tita-z_critico*desvio_titas,self.tita+z_critico*desvio_titas]
    plt.hist(titas_boot,density=True);
    return intervalo,desvio_titas

  def intervalo(self):
    z_critico=norm.ppf(q=1-self.alfa/2)
    desvio=np.sqrt((self.tita*(1-self.tita))/len(self.muestra))
    intervalo=[self.tita-z_critico*desvio,self.tita+z_critico*desvio]
    return intervalo

  def hipotesis_frecuencias(self,probabilidad,frecuencias):
    n=len(probabilidad)-1
    X_obs=sum(((frecuencias-probabilidad)**2)/probabilidad)
    chi_percentil=chi2.ppf(1-self.alfa,n)
    p_valor=1-chi2.cdf(X_obs,n)

    if X_obs > chi_percentil:
      print('el valor observado del estadístico es mayor al percentil de la distribución')
      print('la probabilidad de haber encontrado ese valor o uno más grande:',p_valor)
      print("Rechazamos la hipótesis nula")

    elif X_obs <= chi_percentil:
      print('el valor observado del estadístico es menor o igual al percentil de la distribución')
      print('la probabilidad de haber encontrado ese valor o uno más grande:',p_valor)
      print("No rechazamos la hipótesis nula")

    return p_valor,X_obs,chi_percentil